{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "lPsTvnkpf-3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os"
      ],
      "metadata": {
        "id": "b7TFHZmlxTKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "\n"
      ],
      "metadata": {
        "id": "_DBCEf4FPOpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load directory for image and mask folders\n",
        "image_dir = '/content/drive/MyDrive/Imaging Science MS/Computer Vision/Final Project/Datasets/DESOBA_Dataset/ShadowImage'\n",
        "shadow_mask_dir = '/content/drive/MyDrive/Imaging Science MS/Computer Vision/Final Project/Datasets/DESOBA_Dataset/ShadowMask'\n",
        "instance_mask_dir = '/content/drive/MyDrive/Imaging Science MS/Computer Vision/Final Project/Datasets/DESOBA_Dataset/InstanceMask'\n",
        "\n",
        "# Make a list of all the filenames in each folder\n",
        "image_filenames = os.listdir(image_dir)\n",
        "shadow_mask_filenames = os.listdir(shadow_mask_dir)\n",
        "instance_mask_filenames = os.listdir(instance_mask_dir)\n",
        "\n",
        "# Sort\n",
        "image_filenames.sort()\n",
        "shadow_mask_filenames.sort()\n",
        "instance_mask_filenames.sort()\n",
        "\n",
        "print(len(image_filenames))\n",
        "print(len(shadow_mask_filenames))\n",
        "print(len(instance_mask_filenames))\n",
        "\n",
        "# Combine the directory with each filename\n",
        "image_paths = [os.path.join(image_dir, filename) for filename in image_filenames]\n",
        "shadow_mask_paths = [os.path.join(shadow_mask_dir, filename) for filename in shadow_mask_filenames]\n",
        "instance_mask_paths = [os.path.join(instance_mask_dir, filename) for filename in instance_mask_filenames]\n",
        "\n",
        "# Check if the lists are exactly the same\n",
        "if image_filenames == shadow_mask_filenames == instance_mask_filenames:\n",
        "    print(\"The lists are exactly the same\")\n",
        "else:\n",
        "    print(\"The lists are different\")"
      ],
      "metadata": {
        "id": "XKJMswkIPdqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "9aZKEz7K3D9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "# Convert images to tensors and normalize the mean and std to standard ImageNet stats\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 (required for ResNet)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Create custom dataset class\n",
        "class ShadowDataset(Dataset):\n",
        "    def __init__(self, image_paths, shadow_mask_paths, instance_mask_paths, transform):\n",
        "      self.image_paths = image_paths\n",
        "      self.shadow_mask_paths = shadow_mask_paths\n",
        "      self.instance_mask_paths = instance_mask_paths\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # Read and binarize\n",
        "      image = Image.open(self.image_paths[idx]) # read the image\n",
        "      smask = (np.array(Image.open(self.shadow_mask_paths[idx]).convert('L')) > 0).astype(np.uint8) # read shadow mask and convert to greyscale then binary\n",
        "      imask = (np.array(Image.open(self.instance_mask_paths[idx]).convert('L')) > 0).astype(np.uint8) # read instance mask and convert to greyscale then binary\n",
        "\n",
        "      # Combine into single mask\n",
        "      combined_mask = np.zeros_like(smask, dtype=np.uint8)\n",
        "      combined_mask[smask == 1] = 1  # Shadow\n",
        "      combined_mask[imask == 1] = 2  # Object\n",
        "\n",
        "      # Apply the image transformation\n",
        "      image = self.transform(image)\n",
        "\n",
        "      # Convert mask to tensor and resize (no normalization)\n",
        "      combined_mask = torch.from_numpy(combined_mask).unsqueeze(0).float()  # add channel, float for resizing\n",
        "      combined_mask = F.resize(combined_mask, (224, 224), interpolation=InterpolationMode.NEAREST) # resize, nearest to avoid class mixing\n",
        "      combined_mask = combined_mask.squeeze(0).long()  # Back to (H, W) with integer class labels\n",
        "\n",
        "      return image, combined_mask\n",
        "\n",
        "\n",
        "# Instantiate main dataset\n",
        "dataset = ShadowDataset(image_paths, shadow_mask_paths, instance_mask_paths,transform=transform)\n",
        "\n",
        "# Get index for each partition\n",
        "train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "val_indices, test_indices = train_test_split(val_indices, test_size=0.5, random_state=42)\n",
        "\n",
        "# Partition into subsets\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "\n",
        "# Crate dataloaders for each division\n",
        "batch_size = 32\n",
        "num_workers = 2\n",
        "prefetch_factor = 3\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,num_workers=num_workers,pin_memory=True,prefetch_factor=prefetch_factor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size,shuffle=False,num_workers=num_workers,pin_memory=True,prefetch_factor=prefetch_factor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,shuffle=False,num_workers=num_workers,pin_memory=True,prefetch_factor=prefetch_factor)"
      ],
      "metadata": {
        "id": "AVGa6-3bP-lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "\n",
        "Perform transfer learning on a Unet model using a ResNet18 encoder."
      ],
      "metadata": {
        "id": "zetEswVb48E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the U-Net model\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",        # use ResNet18 as the encoder\n",
        "    encoder_weights=\"imagenet\",     # use the pre-trained ImageNet weights\n",
        "    in_channels=3,                  # RGB input\n",
        "    classes=3,                      # 0 = background | 1 = shadow | 2 = object\n",
        ")\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for multi-class\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# Move model to the GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(\"Using: \",device)\n",
        "\n",
        "#-------------------------- Training loop -------------------------------------\n",
        "\n",
        "# Initialize variables for early stopping\n",
        "best_val_loss = float(\"inf\")\n",
        "best_epoch = -1\n",
        "\n",
        "# keeping track of loss\n",
        "val_loss_history = []\n",
        "train_loss_history = []\n",
        "\n",
        "# For early stopping\n",
        "no_improvement = 0\n",
        "\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    model.train() # set model to training mode\n",
        "    train_losses = [] # reset training losses\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # send input features and reference target to device\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # zeroing out previous step gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # make predictions using the model\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # calculate the gradients by calling backward on the loss\n",
        "        loss.backward()\n",
        "\n",
        "        # take a step by calling step on the optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        # keep score of training loss\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "    train_loss_mean = np.mean(train_losses) # average train loss for current epoch\n",
        "    train_loss_history.append(train_loss_mean) # add to loss per epoch list\n",
        "\n",
        "\n",
        "    #------------------------ Validation Loop ----------------------------------\n",
        "    model.eval() # set model to evaluation mode\n",
        "    val_losses = [] # reset val losses\n",
        "    with torch.no_grad(): # don't update gradients\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # Same as training but we are not updating weights\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "\n",
        "            # validation loss\n",
        "            val_loss = criterion(outputs, y_batch)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "\n",
        "    val_loss_mean = np.mean(val_losses) # average val loss for current epoch\n",
        "    val_loss_history.append(val_loss_mean) # add to loss per epoch list\n",
        "\n",
        "    # Implementing early stopping\n",
        "    if val_loss_mean < best_val_loss:\n",
        "        best_val_loss = val_loss_mean # update the new best val loss\n",
        "        best_epoch = epoch # update the best epoch\n",
        "        torch.save(model.state_dict(), \"best_model.pt\") # save the best model params\n",
        "        no_improvement = 0 # reset time since improvement\n",
        "    else:\n",
        "      no_improvement = no_improvement + 1\n",
        "      if no_improvement >= 15: # early stop if no improvement for 5 epochs\n",
        "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
        "        break\n",
        "\n",
        "\n",
        "    # take a step in the scheduler to update the learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {np.mean(train_losses):.4f} | Val Loss: {val_loss_mean:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "print(f\"\\nBest model saved from epoch {best_epoch+1} with Val Loss: {best_val_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "v-FU0F5bQvcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Training and Validation Loss"
      ],
      "metadata": {
        "id": "cY7ot5uH5xAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(train_loss_history, label='Training Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W2uqw25_XEEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model Performance on Test Set"
      ],
      "metadata": {
        "id": "LEa5pb_V6aX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Imaging Science MS/Computer Vision/Final Project/Datasets/Model Data/best_model.pt\"))\n",
        "model.eval() # set model to evaluation mode\n",
        "\n",
        "# Initialize predicted masks and target masks\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad(): # don't update weights\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device) # send to GPU\n",
        "        outputs = model(X_batch) # use model\n",
        "        preds = torch.argmax(outputs, dim=1) # convert to predicted class maps\n",
        "\n",
        "        # Push to CPU and append the current minibatch\n",
        "        all_preds.append(preds.cpu())\n",
        "        all_targets.append(y_batch.cpu())\n",
        "\n",
        "# Concatenate all batches and flatten all images into a single column\n",
        "all_preds = torch.cat(all_preds).numpy().flatten()\n",
        "all_targets = torch.cat(all_targets).numpy().flatten()\n",
        "\n",
        "# Compute classification metrics\n",
        "test_accuracy = accuracy_score(all_targets, all_preds)\n",
        "test_precision = precision_score(all_targets, all_preds, average='macro')\n",
        "test_recall = recall_score(all_targets, all_preds, average='macro')\n",
        "test_f1 = f1_score(all_targets, all_preds, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\") # how many predictions were true\n",
        "print(f\"Test Precision: {test_precision:.4f}\") # how many positive predictions were true - about being correct when predicting positive\n",
        "print(f\"Test Recall: {test_recall:.4f}\") # how many actual positives were correctly labeled - about catching all the positives\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\") # precision and recall combined\n",
        "\n",
        "# ------------------ Plot Confusion Matrix for Test Data -----------------------\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "class_names = [\"Background\", \"Shadow\", \"Object\"]\n",
        "\n",
        "# Plot the normalized confusion matrix\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # normalize so each row adds up to 1.0\n",
        "cm_normalized = np.round(cm_normalized, 1)  # Round the normalized values to 1 decimal place\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized,display_labels=class_names)\n",
        "disp.plot(ax=ax,cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Normalized)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "36SuzmzO6eyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Performance on a Single Test Image"
      ],
      "metadata": {
        "id": "wp3LYlhU53i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "# Define the U-Net model\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",        # use ResNet18 as the encoder\n",
        "    encoder_weights=\"imagenet\",     # use the pre-trained ImageNet weights\n",
        "    in_channels=3,                  # RGB input\n",
        "    classes=3,                      # 0 = background | 1 = shadow | 2 = object\n",
        ")\n",
        "\n",
        "# Move model to the GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(\"Using: \",device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Imaging Science MS/Computer Vision/Final Project/Datasets/Model Data/best_model.pt\"))\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Get one batch from test loader\n",
        "X_test_batch, y_test_batch = next(iter(test_loader))\n",
        "\n",
        "# pick an image from the batch\n",
        "i = 9\n",
        "\n",
        "# Choose image and mask\n",
        "image = X_test_batch[i].unsqueeze(0).to(device)\n",
        "true_mask = y_test_batch[i].cpu().squeeze().numpy()\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_mask = model(image) # use model\n",
        "    pred_mask_class = torch.argmax(pred_mask, axis=1).cpu().squeeze().numpy() # get class map\n",
        "\n",
        "\n",
        "# Undo normalization before displaying the image\n",
        "std=[0.229, 0.224, 0.225]\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "image = X_test_batch[i].permute(1, 2, 0).cpu().clone()  # [C,H,W] to [H,W,C], clone to not modify the image in place\n",
        "image[:,:,0] = (image[:,:,0] * std[0]) + mean[0]\n",
        "image[:,:,1] = (image[:,:,1] * std[1]) + mean[1]\n",
        "image[:,:,2] = (image[:,:,2] * std[2]) + mean[2]\n",
        "image = torch.clamp(image * 255, 0, 255).byte().numpy()  # Scale to [0, 255] and convert to uint8\n",
        "\n",
        "\n",
        "# Create a colormap for the 3 classes (background, shadow, object)\n",
        "cmap = matplotlib.colormaps[\"tab20\"]\n",
        "\n",
        "# Create a figure with 3 subplots\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# Show input image\n",
        "axs[0].imshow(image)\n",
        "axs[0].set_title(\"Input Image\")\n",
        "axs[0].axis(\"off\")\n",
        "\n",
        "# Show ground truth mask with colormap\n",
        "axs[1].imshow(true_mask, cmap=cmap, vmin=0, vmax=2)  # Show ground truth with color mapping for 3 classes\n",
        "axs[1].set_title(\"Ground Truth Mask\")\n",
        "axs[1].axis(\"off\")\n",
        "\n",
        "# Show predicted mask with colormap\n",
        "axs[2].imshow(pred_mask_class, cmap=cmap, vmin=0, vmax=2)  # Show predicted mask with color mapping for 3 classes\n",
        "axs[2].set_title(\"Predicted Mask\")\n",
        "axs[2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Histogram of image values\n",
        "plt.hist(image.flatten(), bins=256)\n",
        "plt.title(\"Histogram of Input Image Pixels\")\n",
        "plt.xlabel(\"Pixel Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KZEbdh_1nXWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Solar Zenith and Azimuth Angles"
      ],
      "metadata": {
        "id": "JO3VW3fb6POC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICT SOLAR ANGLE USING OBJECT AND IMAGE MASKS\n",
        "\n",
        "# Function: cartesian to polar coords\n",
        "def cart2pol(x,y):\n",
        "    r = np.sqrt(x**2 + y**2)\n",
        "    theta = np.degrees(np.arctan2(y,x))\n",
        "    return r,theta\n",
        "\n",
        "# Function: polar to cartesian coords\n",
        "def pol2cart(r,theta):\n",
        "    x = r * np.cos(theta)\n",
        "    y = r * np.sin(theta)\n",
        "    return x,y\n",
        "\n",
        "# Split the predicted mask into object and shadow based on class\n",
        "object_mask = pred_mask_class == 2\n",
        "shadow_mask = pred_mask_class == 1\n",
        "object_mask = object_mask.astype(np.uint8)\n",
        "shadow_mask = shadow_mask.astype(np.uint8)\n",
        "\n",
        "# Display the masks\n",
        "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
        "ax[0].imshow(object_mask, cmap='grey', vmin=0, vmax=2)\n",
        "ax[0].set_title(\"Object Mask\")\n",
        "ax[0].axis(\"off\")\n",
        "ax[1].imshow(shadow_mask, cmap='grey', vmin=0, vmax=2)\n",
        "ax[1].set_title(\"Shadow Mask\")\n",
        "ax[1].axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(np.unique(object_mask))\n",
        "print(np.unique(shadow_mask))\n",
        "\n",
        "# get locations of mask pixels\n",
        "rows, x = np.where(shadow_mask == 1)\n",
        "y = shadow_mask.shape[0] - rows\n",
        "\n",
        "# fit a line to the shadow points\n",
        "slope, intercept = np.polyfit(x, y, 1) # linear fit\n",
        "x_fit = np.linspace(0,x.max()) # range of x values\n",
        "y_fit = slope * x_fit + intercept # apply slope and intercept to create the line\n",
        "\n",
        "# bias the data by the intercept\n",
        "y_bias = y - intercept # bias the data\n",
        "y_fit_bias = y_fit - intercept # bias the fit line (set y intercept to 0)\n",
        "\n",
        "\n",
        "# show fit line and shadow as scatterplot\n",
        "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "ax[0].scatter(x,y,s=0.01,label='shadow')\n",
        "ax[0].plot(x_fit,y_fit, label='fit',color='r')\n",
        "ax[0].legend()\n",
        "ax[0].set_ylim([0,shadow_mask.shape[0]])\n",
        "ax[0].set_xlim([0,shadow_mask.shape[1]])\n",
        "ax[0].set_title('Shadow With Fit Line')\n",
        "\n",
        "ax[1].scatter(x,y_bias,s=0.01,label='shadow')\n",
        "ax[1].plot(x_fit,y_fit_bias, label='fit',color='r')\n",
        "ax[1].legend()\n",
        "ax[1].set_ylim([0,shadow_mask.shape[0]])\n",
        "ax[1].set_xlim([0,shadow_mask.shape[1]])\n",
        "ax[1].set_title('Shadow With Biased Fit Line')\n",
        "plt.show()\n",
        "\n",
        "# convert fit line to polar coords (degrees)\n",
        "r,theta = cart2pol(x_fit,y_fit_bias)\n",
        "\n",
        "# make angles relative to the vertical (azimuth angle)\n",
        "theta_shadow = np.mean(90 - theta[1:-1]) # average of all points on the line excluding ends\n",
        "\n",
        "# find the length of the shadow\n",
        "rxmin = r[x_fit>x.min()].min() # radial length to first point in shadow (bias)\n",
        "print(\"r at xmin: \",rxmin)\n",
        "rxmax = r[x_fit>x.min()].max() # radial length to last point in shadow\n",
        "print(\"r at xmax: \",rxmax)\n",
        "r_shadow = rxmax - rxmin # radial length of shadow\n",
        "print(\"r_shadow: \",r_shadow)\n",
        "\n",
        "\n",
        "# find height of the object\n",
        "object_height = np.sum(object_mask,axis=1) # add along the columns\n",
        "object_height = object_height[object_height>0] # all nonzero values\n",
        "object_height = object_height.shape[0] # number of vertical obect pixels\n",
        "print(\"object height: \",object_height)\n",
        "\n",
        "# find zenith angle (relative to normal)\n",
        "a = object_height\n",
        "c = r_shadow\n",
        "B = theta_shadow\n",
        "\n",
        "# law of cosines to find 3rd side\n",
        "b2 = a**2 + c**2 - (2 * a * c * np.cos(np.radians(B)))\n",
        "b = np.sqrt(b2)\n",
        "\n",
        "# law of sines to find zenith angle\n",
        "C = np.degrees(np.arcsin( (c * np.sin(np.radians(B))) / b ))\n",
        "\n",
        "# if shadow is to the left of the object, flip the azimuth angle\n",
        "rows_obj, x_obj = np.where(object_mask == 1)\n",
        "x_shadow = x\n",
        "print(\"Shadow average x position: \",np.mean(x_shadow))\n",
        "print(\"Object average x position: \",np.mean(x_obj))\n",
        "\n",
        "# Set quadrant conditions\n",
        "if slope > 0 and np.mean(x_shadow) > np.mean(x_obj): # shadow is in quadrant I\n",
        "  azimuth = theta_shadow\n",
        "elif slope < 0 and np.mean(x_shadow) < np.mean(x_obj): # shadow is in quadrant II\n",
        "  azimuth = theta_shadow + 90\n",
        "elif slope > 0 and np.mean(x_shadow) < np.mean(x_obj): # shadow is in quadrant III\n",
        "    azimuth = theta_shadow + 180\n",
        "elif  slope < 0 and np.mean(x_shadow) > np.mean(x_obj): # shadow is in quadrant IV\n",
        "  azimuth = theta_shadow - 90\n",
        "\n",
        "# predicted solar zenith and azimuth angles\n",
        "zenith = C\n",
        "\n",
        "print(\"\")\n",
        "print(\"zenith angle: \",zenith)\n",
        "print(\"azimuth angle: \",azimuth)\n",
        "\n",
        "# Show input image\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Predicted Solar Azimuth Angle: {azimuth:.2f}°\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Create a figure with 3 subplots\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# Show input image\n",
        "axs[0].imshow(image)\n",
        "axs[0].set_title(f\"Predicted Solar Azimuth Angle: {azimuth:.2f}°\")\n",
        "axs[0].axis(\"off\")\n",
        "\n",
        "# Show ground truth mask with colormap\n",
        "axs[1].imshow(true_mask, cmap=cmap, vmin=0, vmax=2)  # Show ground truth with color mapping for 3 classes\n",
        "axs[1].set_title(\"Ground Truth Mask\")\n",
        "axs[1].axis(\"off\")\n",
        "\n",
        "# Show predicted mask with colormap\n",
        "axs[2].imshow(pred_mask_class, cmap=cmap, vmin=0, vmax=2)  # Show predicted mask with color mapping for 3 classes\n",
        "axs[2].set_title(\"Predicted Mask\")\n",
        "axs[2].axis(\"off\")\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ro_BRJuXHqR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}